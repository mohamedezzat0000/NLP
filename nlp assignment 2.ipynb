{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aba403f",
   "metadata": {},
   "source": [
    "# generate__documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a7801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "def generate_text(num_paragraphs=1):\n",
    "    \n",
    "    faker = Faker()\n",
    "    \n",
    "    return '\\n'.join(faker.paragraph() for i in range(num_paragraphs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30921875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Room community when source sea produce others. Until lawyer general fine career. Common offer total race.\\nFar we staff north interest strategy sport. Always hair environment special few scene.\\nOfficial close dark first wind miss prepare. Alone employee meet maybe project.\\nCustomer PM term Democrat. Condition close probably certain group professor set.\\nHimself visit director garden issue. Whatever fight more rise third must easy movement.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "text_generated_1 = generate_text(5)\n",
    "\n",
    "text_generated_2 = generate_text(5)\n",
    "\n",
    "text_generated_3 = generate_text(5)\n",
    "\n",
    "text_generated_4 = generate_text(5)\n",
    "\n",
    "text_generated_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be40ed8d",
   "metadata": {},
   "source": [
    "# Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750f1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text_generated_1= re.sub(r'[^a-zA-Z0-9\\s]', '', text_generated_1)\n",
    "\n",
    "text_generated_1=text_generated_1.lower()\n",
    "\n",
    "text_generated_2= re.sub(r'[^a-zA-Z0-9\\s]', '', text_generated_2)\n",
    "\n",
    "text_generated_2=text_generated_1.lower()\n",
    "\n",
    "text_generated_3= re.sub(r'[^a-zA-Z0-9\\s]', '', text_generated_3)\n",
    "\n",
    "text_generated_3=text_generated_3.lower()\n",
    "\n",
    "text_generated_4= re.sub(r'[^a-zA-Z0-9\\s]', '', text_generated_4)\n",
    "\n",
    "text_generated_4=text_generated_4.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffdeb8f",
   "metadata": {},
   "source": [
    "# tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eca46508",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_1 = text_generated_1.split()\n",
    "\n",
    "tokens_2 = text_generated_2.split()\n",
    "\n",
    "tokens_3 = text_generated_3.split()\n",
    "\n",
    "tokens_4 = text_generated_4.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b558b3cb",
   "metadata": {},
   "source": [
    "## Convert Docs to Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e1ec614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['room community when source sea produce others until lawyer general fine career common offer total race',\n",
       " 'far we staff north interest strategy sport always hair environment special few scene',\n",
       " 'official close dark first wind miss prepare alone employee meet maybe project',\n",
       " 'customer pm term democrat condition close probably certain group professor set',\n",
       " 'himself visit director garden issue whatever fight more rise third must easy movement']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list_1 = text_generated_1.splitlines()\n",
    "\n",
    "doc_list_2 = text_generated_2.splitlines()\n",
    "\n",
    "doc_list_3 = text_generated_3.splitlines()\n",
    "\n",
    "doc_list_4 = text_generated_4.splitlines()\n",
    "\n",
    "doc_list_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882b590",
   "metadata": {},
   "source": [
    "# Stemming & remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d888718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\MOHAMED-\n",
      "[nltk_data]     LAPTOP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Initialize Porter stemmer\n",
    "stemmer = PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e467a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tokens_1=[stemmer().stem(token)for token in tokens_1 if token not in stop_words]\n",
    "\n",
    "stemmed_tokens_2=[stemmer().stem(token)for token in tokens_2 if token not in stop_words]\n",
    "\n",
    "stemmed_tokens_3=[stemmer().stem(token)for token in tokens_3 if token not in stop_words]\n",
    "\n",
    "stemmed_tokens_4=[stemmer().stem(token)for token in tokens_4 if token not in stop_words]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248f6fa",
   "metadata": {},
   "source": [
    "# Get Unique Words After Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9208d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_1 = set(stemmed_tokens_1)\n",
    "\n",
    "unique_2 = set(stemmed_tokens_2)\n",
    "\n",
    "unique_3 = set(stemmed_tokens_3)\n",
    "\n",
    "unique_4 = set(stemmed_tokens_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8855b4",
   "metadata": {},
   "source": [
    "# Get TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e782a28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['agreement' 'always' 'and' 'anyone' 'arm' 'around' 'assume' 'attack'\n",
      " 'author' 'authority' 'available' 'baby' 'bill' 'bring' 'capital' 'car'\n",
      " 'child' 'cold' 'computer' 'crime' 'customer' 'decision' 'door' 'employee'\n",
      " 'far' 'figure' 'fine' 'friend' 'full' 'fund' 'growth' 'hand' 'health'\n",
      " 'hear' 'heavy' 'him' 'image' 'institution' 'issue' 'language' 'lay'\n",
      " 'light' 'matter' 'measure' 'medical' 'minute' 'month' 'mr' 'national'\n",
      " 'natural' 'near' 'occur' 'others' 'owner' 'parent' 'price' 'professor'\n",
      " 'prove' 'push' 'recent' 'rest' 'right' 'role' 'sell' 'service' 'simply'\n",
      " 'society' 'soon' 'stay' 'stuff' 'such' 'sure' 'take' 'teacher' 'test'\n",
      " 'then' 'through' 'tough' 'view' 'wall' 'watch' 'white' 'win' 'yard'\n",
      " 'year' 'yet']\n",
      "TF-IDF matrix:\n",
      "[[0.         0.         0.20018928 0.20018928 0.         0.20018928\n",
      "  0.20018928 0.16151145 0.20018928 0.         0.         0.\n",
      "  0.         0.20018928 0.         0.         0.         0.\n",
      "  0.         0.20018928 0.         0.         0.20018928 0.\n",
      "  0.         0.         0.20018928 0.         0.         0.\n",
      "  0.         0.20018928 0.         0.20018928 0.         0.\n",
      "  0.         0.20018928 0.         0.20018928 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.20018928 0.\n",
      "  0.         0.20018928 0.         0.         0.20018928 0.\n",
      "  0.20018928 0.20018928 0.         0.         0.20018928 0.\n",
      "  0.         0.         0.         0.         0.20018928 0.\n",
      "  0.         0.16151145 0.20018928 0.         0.         0.\n",
      "  0.         0.         0.         0.20018928 0.20018928 0.\n",
      "  0.         0.16151145]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.26726124 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.26726124 0.         0.26726124 0.         0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.         0.         0.26726124 0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.26726124 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26726124\n",
      "  0.26726124 0.         0.         0.         0.         0.26726124\n",
      "  0.26726124 0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.31622777 0.         0.         0.31622777 0.31622777 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.31622777 0.\n",
      "  0.         0.         0.31622777 0.         0.31622777 0.\n",
      "  0.         0.         0.         0.         0.         0.31622777\n",
      "  0.         0.         0.         0.         0.         0.31622777\n",
      "  0.         0.31622777 0.         0.         0.         0.\n",
      "  0.         0.         0.31622777 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.24253563 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24253563\n",
      "  0.         0.         0.         0.         0.         0.24253563\n",
      "  0.24253563 0.         0.24253563 0.24253563 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.24253563\n",
      "  0.         0.         0.         0.         0.         0.24253563\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24253563 0.24253563 0.24253563 0.         0.\n",
      "  0.         0.         0.24253563 0.         0.         0.\n",
      "  0.         0.         0.         0.24253563 0.         0.24253563\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.24253563 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24253563 0.         0.         0.         0.\n",
      "  0.24253563 0.        ]\n",
      " [0.         0.21846381 0.         0.         0.21846381 0.\n",
      "  0.         0.17625523 0.         0.21846381 0.21846381 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21846381\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.21846381 0.         0.21846381 0.         0.21846381 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.21846381 0.         0.21846381\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.21846381 0.         0.         0.21846381\n",
      "  0.21846381 0.21846381 0.         0.21846381 0.         0.\n",
      "  0.         0.17625523 0.         0.21846381 0.21846381 0.\n",
      "  0.         0.         0.21846381 0.         0.         0.21846381\n",
      "  0.         0.17625523]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(doc_list_4)\n",
    "\n",
    "print(\"Feature names:\", tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"TF-IDF matrix:\")\n",
    "print(tfidf_features.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42d811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
